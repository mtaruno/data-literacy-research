{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 7 - Topic extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this notebook you will need to be running the most recent version of scikit-learn.  \n",
    "Make sure you have at least version 17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "# Suppress warnings from pandas library\n",
    "\n",
    "import nltk\n",
    "pd.set_option('display.max_colwidth', 150000) #important for getting all the text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic extraction and application \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's talk about Non-negative Matrix Factorization.\n",
    "\n",
    "Our vector spaces are also matrices and we can split them (factor them) into two components in which all the entries are positive or zero (non-negative). Why?\n",
    "\n",
    "What if the thing we are trying to get at isn't actually represented by the numbers in our matrix?  What if they represent some unobserved (\"latent\") characteristic that we want to approximate?\n",
    "Example:  Movie reviews - the number you give to a particular movie may also reflect your feelings about the actors, directon, or genre as much as the individual movie. \n",
    "For this analysis: the topic you are looking to extract and apply to a particular document may not be represented by word that actually appears in that document.  (Remember the \"base\", \"hit\", \"homer\" example).\n",
    "\n",
    "By factoring the matrix, we can fill in the matrix so it isn't so sparse and we can better apply the labels that capture some of the latent features for a document.\n",
    "\n",
    "Math: http://www.slideshare.net/BenjaminBengfort/non-negative-matrix-factorization\n",
    "\n",
    "Another example: https://de.dariah.eu/tatom/topic_model_python.html\n",
    "\n",
    "https://robinsones.github.io/Topic-Modeling-the-New-York-Times-and-Trump/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the example math from above to show how the factorization works\n",
    "import numpy\n",
    "\n",
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - numpy.dot(P[i,:],Q[:,j])\n",
    "                    for k in range(K):\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = numpy.dot(P,Q)\n",
    "        e = 0\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - numpy.dot(P[i,:],Q[:,j]), 2)\n",
    "                    for k in range(K):\n",
    "                        e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = [\n",
    "     [5,3,0,1],\n",
    "     [4,0,0,1],\n",
    "     [1,1,0,5],\n",
    "     [1,0,0,4],\n",
    "     [0,1,5,4],\n",
    "    ]\n",
    " \n",
    "R = np.array(R)\n",
    "\n",
    "N = len(R)\n",
    "M = len(R[0])\n",
    "K = 2\n",
    " \n",
    "P = np.random.rand(N,K)\n",
    "Q = np.random.rand(M,K)\n",
    " \n",
    "nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "nR = np.dot(nP, nQ.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 3 0 1]\n",
      " [4 0 0 1]\n",
      " [1 1 0 5]\n",
      " [1 0 0 4]\n",
      " [0 1 5 4]]\n",
      "~~~~~~~~~~~~~~~~\n",
      "[[ 2.34270556 -0.19845106]\n",
      " [ 1.866818   -0.06908812]\n",
      " [ 0.8207655   1.96608698]\n",
      " [ 0.70065436  1.56158232]\n",
      " [ 1.15613634  1.46313113]]\n",
      "~~~~~~~~~~~~~~~~\n",
      "[[ 2.10763731 -0.33086903]\n",
      " [ 1.23488645 -0.11099837]\n",
      " [ 2.23750482  1.58118649]\n",
      " [ 0.61819314  2.26703334]]\n",
      "~~~~~~~~~~~~~~~~\n",
      "[[5.00323494 2.91500309 4.92802685 0.99834933]\n",
      " [3.95743438 2.31297692 4.06777308 0.99742902]\n",
      " [1.0793587  0.79531974 4.94521691 4.96457632]\n",
      " [0.96004605 0.69189549 4.03687038 3.9732989 ]\n",
      " [1.95261132 1.26529193 4.90034381 4.03168261]]\n"
     ]
    }
   ],
   "source": [
    "print(R)\n",
    "print(\"~~~~~~~~~~~~~~~~\")\n",
    "print(P)\n",
    "print(\"~~~~~~~~~~~~~~~~\")\n",
    "print(Q)\n",
    "print(\"~~~~~~~~~~~~~~~~\")\n",
    "print(nR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine learning is super fun', 'Python is super, super cool', 'Statistics is cool, too', 'Fun? Data science is more than fun', 'Python is great for machine learning', 'I like football', 'Football is great to watch']\n",
      "[[0.         0.         0.         0.5        0.         0.5\n",
      "  0.         0.5        0.         0.         0.         0.5\n",
      "  0.        ]\n",
      " [0.40824829 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.40824829 0.         0.         0.81649658\n",
      "  0.        ]\n",
      " [0.70710678 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.70710678 0.\n",
      "  0.        ]\n",
      " [0.         0.40824829 0.         0.81649658 0.         0.\n",
      "  0.         0.         0.         0.40824829 0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.5        0.5\n",
      "  0.         0.5        0.5        0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.70710678 0.         0.         0.\n",
      "  0.70710678 0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.57735027 0.         0.57735027 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.57735027]]\n"
     ]
    }
   ],
   "source": [
    "#what about our group text example?\n",
    "\n",
    "\n",
    "friend1 = \"Machine learning is super fun\"\n",
    "friend2 = \"Python is super, super cool\"\n",
    "friend3 = \"Statistics is cool, too\"\n",
    "friend4 = \"Fun? Data science is more than fun\"\n",
    "friend5 = \"Python is great for machine learning\"\n",
    "friend6 = \"I like football\"\n",
    "friend7 = \"Football is great to watch\"\n",
    "textStr = [friend1, friend2, friend3, friend4, friend5, friend6, friend7]\n",
    "print(textStr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cvnorm = TfidfVectorizer(binary=False, stop_words='english', use_idf = False) #default is to normalize\n",
    "cvnorm_dm = cvnorm.fit_transform(textStr)\n",
    "print(cvnorm_dm.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30308779 0.25060509 0.67170275 0.47417101 0.38702892 0.54861057\n",
      "  0.35659203 0.50594075 0.16080538 0.44223947 0.2960322  0.44683018\n",
      "  0.5697743 ]\n",
      " [0.53422802 0.57300349 0.887964   0.8535573  0.76010818 0.90628848\n",
      "  0.75535629 0.7459321  0.44368831 0.7104549  0.64273132 0.7864986\n",
      "  0.86362123]\n",
      " [0.55153099 0.63650945 0.81538559 0.88728853 0.81140593 0.91485936\n",
      "  0.82324088 0.72015791 0.51292348 0.70982695 0.70495462 0.8115983\n",
      "  0.8434306 ]\n",
      " [0.38636829 0.49558468 0.45918612 0.62830632 0.59791199 0.61791982\n",
      "  0.62470851 0.44929942 0.41997118 0.47112974 0.53961872 0.56814185\n",
      "  0.53761515]\n",
      " [0.34859759 0.45731127 0.39135816 0.56826168 0.54550008 0.55280873\n",
      "  0.57346641 0.39407375 0.39133454 0.41972211 0.49623907 0.51251662\n",
      "  0.47415693]\n",
      " [0.44571866 0.50116502 0.68877812 0.71526934 0.64788398 0.7454585\n",
      "  0.65252124 0.59669072 0.39837034 0.58060256 0.55752105 0.65600161\n",
      "  0.69579184]\n",
      " [0.36868983 0.40717011 0.58639171 0.59065719 0.53153429 0.62004298\n",
      "  0.53261999 0.50177411 0.32051109 0.48414652 0.45436845 0.54269325\n",
      "  0.58345757]]\n"
     ]
    }
   ],
   "source": [
    "R = numpy.array(cvnorm_dm.toarray())\n",
    "\n",
    "N = len(R)\n",
    "M = len(R[0])\n",
    "K = 2\n",
    " \n",
    "P = numpy.random.rand(N,K)\n",
    "Q = numpy.random.rand(M,K)\n",
    " \n",
    "nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "nR = numpy.dot(nP, nQ.T)\n",
    "print(nR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cool', 'data', 'football', 'fun', 'great', 'learning', 'like', 'machine', 'python', 'science', 'statistics', 'super', 'watch']\n"
     ]
    }
   ],
   "source": [
    "#transforms the matrix so that it can extract feature names that may apply to the topic in a document\n",
    "# even if that feature name doesn't appear in that document.\n",
    "\n",
    "#But you don't need to do the math directly\n",
    "from sklearn.decomposition import NMF\n",
    "n_topics = 3\n",
    "n_top_words = 2\n",
    "\n",
    "# Fit the NMF model\n",
    "nmf = NMF(n_components=n_topics, random_state=1).fit(cvnorm_dm)\n",
    "\n",
    "\n",
    "names_texts = cvnorm.get_feature_names()\n",
    "\n",
    "print(names_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "3\n",
      "[[0.         0.16521867 0.         0.66965112 0.21701335 0.58223715\n",
      "  0.         0.58223715 0.30339442 0.16521867 0.         0.45984276\n",
      "  0.        ]\n",
      " [0.         0.         0.78442041 0.         0.40568026 0.01598515\n",
      "  0.42295974 0.01598515 0.03754171 0.         0.         0.\n",
      "  0.36146067]\n",
      " [0.6775754  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.15622711 0.         0.48415424 0.33782021\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(type(nmf.components_))\n",
    "print(len(nmf.components_))\n",
    "print(nmf.components_)\n",
    "text_components = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nice function for printing topic information - \n",
    "# https://stackoverflow.com/questions/34429635/topic-modelling-assign-a-document-with-top-2-topics-as-category-label-sklear\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics for texts in NMF model:\n",
      "Topic #0:\n",
      "fun machine\n",
      "Topic #1:\n",
      "football like\n",
      "Topic #2:\n",
      "cool statistics\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics for texts in NMF model:\")\n",
    "print_top_words(nmf, names_texts, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3848, 5)\n",
      "['date', 'description', 'headline', 'url', 'text']\n"
     ]
    }
   ],
   "source": [
    "# a \"real\" example - let's torture the news articles again\n",
    "\n",
    "newsdf = pd.read_csv(\"nytimes2013.csv\", index_col = 0) \n",
    "print(newsdf.shape)\n",
    "print(list(newsdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a little preprocessing\n",
    "import re\n",
    "news_dict = {'united states':'usa','states':'state', 'years':'year',\n",
    "             'new york': 'ny', 'republicans':'republican', 'schools':'school',\n",
    "            'companies':'company', 'de blasio':'nymayor'}\n",
    "\n",
    "\n",
    "\n",
    "def multiple_replace(dict, text): \n",
    "\n",
    "  \"\"\" Replace in 'text' all occurences of any key in the given\n",
    "  dictionary by its corresponding value.  Returns the new tring.\"\"\" \n",
    "  text = str(text).lower()\n",
    "\n",
    "  # Create a regular expression  from the dictionary keys\n",
    "  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
    "\n",
    "  # For each match, look-up corresponding value in dictionary\n",
    "  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text)\n",
    "\n",
    "newsdf['cleantext'] = newsdf.text.apply(lambda x: multiple_replace(news_dict, x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3848, 1110)\n",
      "<class 'list'> 1110\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "skl_stopwords = list(text.ENGLISH_STOP_WORDS)\n",
    "\n",
    "#stop words didn't get saved, need to recreate that list\n",
    "my_stopwords = skl_stopwords + [\"mr\", \"ms\", \"say\",\"said\", \"0\", '000','10', '100', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '200', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '21', '22', '23', '24', '25', '27', '30', '300', '35', '40', '45', '50', '500', '60', '70', '80']\n",
    "\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=True, \n",
    "                        stop_words= my_stopwords, \n",
    "                        max_df=0.95, \n",
    "                        min_df=0.05) \n",
    "\n",
    "# fit and transform text\n",
    "\n",
    "tfidf_dm = tfidf.fit_transform(newsdf['cleantext'])\n",
    "\n",
    "#print matrix shape(s)\n",
    "print(tfidf_dm.shape)\n",
    "names_news = tfidf.get_feature_names()\n",
    "print(type(names_news), len(names_news))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110\n",
      "\n",
      "Topics for news in NMF model:\n",
      "Topic #0:\n",
      "like just year time don\n",
      "Topic #1:\n",
      "military obama american officials government\n",
      "Topic #2:\n",
      "game team season players games\n",
      "Topic #3:\n",
      "republican senate house democrats senator\n",
      "Topic #4:\n",
      "company percent industry market year\n",
      "Topic #5:\n",
      "city mayor ny police brooklyn\n",
      "Topic #6:\n",
      "court justice case state law\n",
      "Topic #7:\n",
      "school students education children college\n",
      "Topic #8:\n",
      "health insurance care state law\n",
      "Topic #9:\n",
      "dr women study medical research\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_topics = 10\n",
    "n_top_words = 5\n",
    "\n",
    "# Fit the NMF model\n",
    "nmf = NMF(n_components=n_topics, random_state=1).fit(tfidf_dm)\n",
    "news_components_10_5 = nmf.components_\n",
    "\n",
    "names_news = tfidf.get_feature_names()\n",
    "print(len(names_news))\n",
    "\n",
    "print(\"\\nTopics for news in NMF model:\")\n",
    "print_top_words(nmf, names_news, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where you decipher these collections of words to decide whether they make sense.  Maybe 10 topics is too many - are any of these \"overlapping\"?  Is 5 words the right number to capture distinctions?\n",
    "\n",
    "Let's try to put labels on the different collections:\n",
    "* Topic 0: \n",
    "* Topic 1: \n",
    "* Topic 2: \n",
    "* Topic 3: \n",
    "* Topic 4: \n",
    "* Topic 5: \n",
    "* Topic 6: \n",
    "* Topic 7:\n",
    "* Topic 8: \n",
    "* Topic 9: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110\n",
      "\n",
      "Topics for news in NMF model:\n",
      "Topic #0:\n",
      "like year just time old family people don mother life didn know way home day good ny ve told make\n",
      "Topic #1:\n",
      "military obama american officials government usa president weapons security administration intelligence official war foreign al forces nations china minister attack\n",
      "Topic #2:\n",
      "game team season players games league play coach teams player fans field ball year win world second played playing goal\n",
      "Topic #3:\n",
      "republican senate house democrats senator obama vote party legislation president state law congress conservative democrat democratic budget representative health spending\n",
      "Topic #4:\n",
      "company percent city state health school year federal people students million new dr law care insurance workers ny industry public\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try different configurations\n",
    "# fewer topics, lots of words\n",
    "n_topics = 5\n",
    "n_top_words = 20\n",
    "\n",
    "# Fit the NMF model\n",
    "nmf = NMF(n_components=n_topics, random_state=1).fit(tfidf_dm)\n",
    "news_components_5_5 = nmf.components_\n",
    "\n",
    "names_news = tfidf.get_feature_names()\n",
    "print(len(names_news))\n",
    "\n",
    "print(\"\\nTopics for news in NMF model:\")\n",
    "print_top_words(nmf, names_news, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can see that sports, politics, government, and our wild card category are pretty much the same but now business, local, and health are lumped together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110\n",
      "\n",
      "Topics for news in NMF model:\n",
      "Topic #0:\n",
      "like don just people think\n",
      "Topic #1:\n",
      "military government american weapons officials\n",
      "Topic #2:\n",
      "game team games season play\n",
      "Topic #3:\n",
      "republican senate democrats senator house\n",
      "Topic #4:\n",
      "company data industry technology information\n",
      "Topic #5:\n",
      "city mayor ny campaign brooklyn\n",
      "Topic #6:\n",
      "court justice judge case law\n",
      "Topic #7:\n",
      "school students education college student\n",
      "Topic #8:\n",
      "health insurance care law plans\n",
      "Topic #9:\n",
      "dr study medical research university\n",
      "Topic #10:\n",
      "police officers department crime enforcement\n",
      "Topic #11:\n",
      "food oil water add restaurant\n",
      "Topic #12:\n",
      "building street apartment park buildings\n",
      "Topic #13:\n",
      "obama president administration white house\n",
      "Topic #14:\n",
      "percent market tax year economy\n",
      "Topic #15:\n",
      "women men woman sex book\n",
      "Topic #16:\n",
      "mother family father children parents\n",
      "Topic #17:\n",
      "china usa party north countries\n",
      "Topic #18:\n",
      "state new jersey laws federal\n",
      "Topic #19:\n",
      "players league season player team\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#more topics, fewer words\n",
    "n_topics = 20\n",
    "n_top_words = 5\n",
    "\n",
    "# Fit the NMF model\n",
    "nmf = NMF(n_components=n_topics, random_state=1).fit(tfidf_dm)\n",
    "news_components_20_5 = nmf.components_\n",
    "\n",
    "names_news = tfidf.get_feature_names()\n",
    "print(len(names_news))\n",
    "\n",
    "print(\"\\nTopics for news in NMF model:\")\n",
    "print_top_words(nmf, names_news, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once you are happy with the topic assignment, it's time to label each document with the appropriate comment.\n",
    "\n",
    "#### What does \"appropriate\" mean?  It's the label CLOSEST to the document content.  \n",
    "\n",
    "Yup, this is where all that distance and similarity stuff comes in.  We'll use those calculations to decided which topic label we want to apply to each document.\n",
    "\n",
    "(Why are we doing this?  Remember, classification is one of the reasons we do data mining.  This is a form of classification.  We can also use it for prediction:  build predictive models to assign topics based on the model we can build from this training dataset. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#define a function for cosine similarity - the latest version in sklearn doesn't take vectors\n",
    "def cosine_similarity(a, b):\n",
    "    return sum([i*j for i,j in zip(a, b)])/(math.sqrt(sum([i*i for i in a]))* math.sqrt(sum([i*i for i in b])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   text\n",
      "0         Machine learning is super fun\n",
      "1           Python is super, super cool\n",
      "2               Statistics is cool, too\n",
      "3    Fun? Data science is more than fun\n",
      "4  Python is great for machine learning\n",
      "5                       I like football\n",
      "6            Football is great to watch\n"
     ]
    }
   ],
   "source": [
    "#let's make a  dataframe\n",
    "textdf = pd.DataFrame(textStr)\n",
    "textdf.columns = ['text']\n",
    "print(textdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for determining the most similar topic\n",
    "# credit Leo Ji\n",
    "\n",
    "def topic_sim(arr, feature_names, n_top_words, topics):\n",
    "    \"\"\"\n",
    "    @type  arr: array of number\n",
    "    @param arr: vectorizer number in an array.\n",
    "    @type  feature_names: array of string\n",
    "    @param feature_names: The array of feature names.\n",
    "    @type  n_top_words: number\n",
    "    @param n_top_words: The number of topics to return.\n",
    "    @type  topics: array of string\n",
    "    @param topics: Complete list of topics from topic extraction.\n",
    "    \n",
    "    @rtype:   top topics\n",
    "    @return:  top topics in string separated by space.\n",
    "    \"\"\"\n",
    "    top_sim = 0\n",
    "    top_topic = np.array([])\n",
    "    # iterate over topics\n",
    "    for idx, topic in enumerate(topics):\n",
    "        # calculate cosine similarity - substitute euclidean distance if that is your preferred metric\n",
    "        # could switch to euclidean_distances\n",
    "        sim = cosine_similarity(arr, topic)\n",
    "        if sim > top_sim:\n",
    "            top_sim = sim\n",
    "            top_topic = topic\n",
    "    \n",
    "    # argsort sort is in ascending order, so pick last n_top_words from it\n",
    "    selected_topic_index = top_topic.argsort()[:-n_top_words-1:-1]\n",
    "    # return the text feature names by indeing back into feature_names (assigned earlier)   \n",
    "    return \" \".join([feature_names[i] for i in selected_topic_index])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>nmf_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine learning is super fun</td>\n",
       "      <td>fun machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python is super, super cool</td>\n",
       "      <td>cool statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Statistics is cool, too</td>\n",
       "      <td>cool statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fun? Data science is more than fun</td>\n",
       "      <td>fun machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python is great for machine learning</td>\n",
       "      <td>fun machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I like football</td>\n",
       "      <td>football like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Football is great to watch</td>\n",
       "      <td>football like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text       nmf_topics\n",
       "0         Machine learning is super fun      fun machine\n",
       "1           Python is super, super cool  cool statistics\n",
       "2               Statistics is cool, too  cool statistics\n",
       "3    Fun? Data science is more than fun      fun machine\n",
       "4  Python is great for machine learning      fun machine\n",
       "5                       I like football    football like\n",
       "6            Football is great to watch    football like"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a vector of topic labels that can be appended to the original dataframe\n",
    "textdf['nmf_topics'] = np.ma.apply_along_axis(topic_sim, axis=1, \n",
    "        arr=cvnorm_dm.toarray(), feature_names=cvnorm.get_feature_names(), n_top_words=2, topics=text_components)\n",
    "textdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553.9061460494995"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's apply this to the news example - this takes some time\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "\n",
    "\n",
    "#apply most similar topic to each document\n",
    "newsdf['topics_20_5'] = np.ma.apply_along_axis(topic_sim, axis=1, \n",
    "        arr=tfidf_dm.toarray(), feature_names=names_news, n_top_words=5, topics=news_components_20_5)\n",
    "t1 = time.time()\n",
    "\n",
    "t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "like don just people think                        751\n",
       "military government american weapons officials    317\n",
       "game team games season play                       271\n",
       "republican senate democrats senator house         213\n",
       "company data industry technology information      209\n",
       "percent market tax year economy                   204\n",
       "building street apartment park buildings          198\n",
       "mother family father children parents             179\n",
       "food oil water add restaurant                     178\n",
       "city mayor ny campaign brooklyn                   175\n",
       "players league season player team                 150\n",
       "court justice judge case law                      141\n",
       "obama president administration white house        140\n",
       "dr study medical research university              139\n",
       "school students education college student         125\n",
       "health insurance care law plans                   116\n",
       "police officers department crime enforcement      111\n",
       "state new jersey laws federal                      93\n",
       "women men woman sex book                           70\n",
       "china usa party north countries                    68\n",
       "Name: topics_20_5, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count topics and view dataframe\n",
    "\n",
    "newsdf['topics_20_5'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>topics_20_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ending a climactic showdown in the final hours of the 112th Congress, the House sent to President Obama legislation to avert big income tax increases on most Americans.</td>\n",
       "      <td>republican senate democrats senator house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A report on nearly three million people found that those whose body mass index ranked them as overweight had less risk of dying than people of normal weight.</td>\n",
       "      <td>dr study medical research university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As the United States prepares to withdraw from an unpopular war in Afghanistan, it faces challenges similar to what the country’s last occupier, the Soviet Union, had experienced.</td>\n",
       "      <td>military government american weapons officials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The popularity of the drinks reflects success in convincing consumers that they provide an edge, but most of their ingredients have no or little benefit, research shows.</td>\n",
       "      <td>dr study medical research university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Hampshire, which again chose a woman to be governor, will also become the first state in history to have an all-female delegation in Washington.</td>\n",
       "      <td>women men woman sex book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>For a 65th birthday, a first burial pitch.</td>\n",
       "      <td>like don just people think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The United Nations’ human rights chief, Navi Pillay, on Wednesday voiced dismay over an analysis that far exceeds earlier estimates of the toll in 22-month-old war.</td>\n",
       "      <td>military government american weapons officials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The depth of the anger that followed the House’s refusal to take up a package of assistance for Hurricane Sandy victims was extraordinary and exceedingly personal.</td>\n",
       "      <td>republican senate democrats senator house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How the breakout star (and daughter of David) turned “Girls” from a show about a trio to one about a quartet.</td>\n",
       "      <td>like don just people think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Three memorable television characters who dressed for success (and sometimes to excess).</td>\n",
       "      <td>women men woman sex book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                           description  \\\n",
       "0             Ending a climactic showdown in the final hours of the 112th Congress, the House sent to President Obama legislation to avert big income tax increases on most Americans.   \n",
       "1                        A report on nearly three million people found that those whose body mass index ranked them as overweight had less risk of dying than people of normal weight.   \n",
       "2  As the United States prepares to withdraw from an unpopular war in Afghanistan, it faces challenges similar to what the country’s last occupier, the Soviet Union, had experienced.   \n",
       "3            The popularity of the drinks reflects success in convincing consumers that they provide an edge, but most of their ingredients have no or little benefit, research shows.   \n",
       "4                                 New Hampshire, which again chose a woman to be governor, will also become the first state in history to have an all-female delegation in Washington.   \n",
       "5                                                                                                                                           For a 65th birthday, a first burial pitch.   \n",
       "6                 The United Nations’ human rights chief, Navi Pillay, on Wednesday voiced dismay over an analysis that far exceeds earlier estimates of the toll in 22-month-old war.   \n",
       "7                  The depth of the anger that followed the House’s refusal to take up a package of assistance for Hurricane Sandy victims was extraordinary and exceedingly personal.   \n",
       "8                                                                        How the breakout star (and daughter of David) turned “Girls” from a show about a trio to one about a quartet.   \n",
       "9                                                                                             Three memorable television characters who dressed for success (and sometimes to excess).   \n",
       "\n",
       "                                      topics_20_5  \n",
       "0       republican senate democrats senator house  \n",
       "1            dr study medical research university  \n",
       "2  military government american weapons officials  \n",
       "3            dr study medical research university  \n",
       "4                        women men woman sex book  \n",
       "5                      like don just people think  \n",
       "6  military government american weapons officials  \n",
       "7       republican senate democrats senator house  \n",
       "8                      like don just people think  \n",
       "9                        women men woman sex book  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsdf[['description','topics_20_5']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are other methods for doing topic extraction\n",
    "\n",
    "#### Latent Dirichlet Allocation\n",
    "* Introduction: http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/\n",
    "\n",
    "LDA assumes documents are produced from a mixture of topics. Those topics then generate words based on their probability distribution, like the ones in our walkthrough model. In other words, LDA assumes a document is made from the following steps:\n",
    "\n",
    "* Determine the number of words in a document. Let’s say our document has 6 words.\n",
    "* Determine the mixture of topics in that document. For example, the document might contain 1/2 the topic “health” and 1/2 the topic “vegetables.”\n",
    "* Using each topic’s multinomial distribution, output words to fill the document’s word slots. In our example, the “health” topic is 1/2 our document, or 3 words. The “health” topic might have the word “diet” at 20% probability or “exercise” at 15%, so it will fill the document word slots based on those probabilities.\n",
    "* Given this assumption of how documents are created, LDA backtracks and tries to figure out what topics would create those documents in the first place.\n",
    "\n",
    "(from: https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html\n",
    "\n",
    "Another version of the same example: https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/\n",
    "\n",
    "These use the gensim package rather than sklearn.)\n",
    "\n",
    "Remember this example?  http://brandonrose.org/clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics for texts in LDA model:\n",
      "Topic #0:\n",
      "cool football\n",
      "Topic #1:\n",
      "fun data\n",
      "Topic #2:\n",
      "watch super\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "n_topics = 3\n",
    "n_top_words = 2\n",
    "\n",
    "# Fit the LDA model\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, max_iter=5,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(cvnorm_dm)\n",
    "\n",
    "feature_names = cvnorm.get_feature_names()\n",
    "\n",
    "#what are the topics for this corpus?\n",
    "print(\"\\nTopics for texts in LDA model:\")\n",
    "print_top_words(lda, feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.37 ms, sys: 562 µs, total: 3.93 ms\n",
      "Wall time: 4.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#apply most similar topic to each document\n",
    "textdf['lda_topics'] = np.ma.apply_along_axis(topic_sim, axis=1, \n",
    "        arr=cvnorm_dm.toarray(), feature_names=cvnorm.get_feature_names(), n_top_words=2, topics=lda.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>nmf_topics</th>\n",
       "      <th>lda_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine learning is super fun</td>\n",
       "      <td>fun machine</td>\n",
       "      <td>watch super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python is super, super cool</td>\n",
       "      <td>cool statistics</td>\n",
       "      <td>cool football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Statistics is cool, too</td>\n",
       "      <td>cool statistics</td>\n",
       "      <td>cool football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fun? Data science is more than fun</td>\n",
       "      <td>fun machine</td>\n",
       "      <td>fun data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python is great for machine learning</td>\n",
       "      <td>fun machine</td>\n",
       "      <td>fun data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I like football</td>\n",
       "      <td>football like</td>\n",
       "      <td>cool football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Football is great to watch</td>\n",
       "      <td>football like</td>\n",
       "      <td>watch super</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text       nmf_topics     lda_topics\n",
       "0         Machine learning is super fun      fun machine    watch super\n",
       "1           Python is super, super cool  cool statistics  cool football\n",
       "2               Statistics is cool, too  cool statistics  cool football\n",
       "3    Fun? Data science is more than fun      fun machine       fun data\n",
       "4  Python is great for machine learning      fun machine       fun data\n",
       "5                       I like football    football like  cool football\n",
       "6            Football is great to watch    football like    watch super"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics for news in LDA model:\n",
      "Topic #0:\n",
      "women china children company college\n",
      "Topic #1:\n",
      "officers police says government department\n",
      "Topic #2:\n",
      "cases year chicago american office\n",
      "Topic #3:\n",
      "republican senate state health obama\n",
      "Topic #4:\n",
      "company market year like people\n",
      "Topic #5:\n",
      "military government police obama officials\n",
      "Topic #6:\n",
      "music energy year dr child\n",
      "Topic #7:\n",
      "year like team people just\n",
      "Topic #8:\n",
      "city year company women school\n",
      "Topic #9:\n",
      "republican vote director senate american\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#and the news stories?\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "n_topics = 10\n",
    "n_top_words = 5\n",
    "\n",
    "# Fit the NMF model\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, max_iter=5,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(tfidf_dm)\n",
    "\n",
    "feature_names = tfidf.get_feature_names()\n",
    "\n",
    "print(\"\\nTopics for news in LDA model:\")\n",
    "print_top_words(lda, feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics for news in LDA model:\n",
      "Topic #0:\n",
      "children dr child school city\n",
      "Topic #1:\n",
      "mayor year games children health\n",
      "Topic #2:\n",
      "year like team game just\n",
      "Topic #3:\n",
      "love state daughter building million\n",
      "Topic #4:\n",
      "teams research report defense percent\n",
      "Topic #5:\n",
      "military officials women government rules\n",
      "Topic #6:\n",
      "music base space year place\n",
      "Topic #7:\n",
      "company story city death car\n",
      "Topic #8:\n",
      "building buildings street apartment west\n",
      "Topic #9:\n",
      "republican senate vote house book\n",
      "Topic #10:\n",
      "city mayor people says bar\n",
      "Topic #11:\n",
      "american police intelligence security attack\n",
      "Topic #12:\n",
      "father table class china mother\n",
      "Topic #13:\n",
      "city air rights people age\n",
      "Topic #14:\n",
      "building house president obama white\n",
      "Topic #15:\n",
      "republican state government obama year\n",
      "Topic #16:\n",
      "read ny job neighborhood tell\n",
      "Topic #17:\n",
      "minister prime private president leader\n",
      "Topic #18:\n",
      "school like year bar students\n",
      "Topic #19:\n",
      "company north french women students\n",
      "\n",
      "CPU times: user 1min 29s, sys: 1.91 s, total: 1min 30s\n",
      "Wall time: 53.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_topics = 20\n",
    "n_top_words = 5\n",
    "\n",
    "# Fit the model\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, max_iter=50,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(tfidf_dm)\n",
    "\n",
    "feature_names = tfidf.get_feature_names()\n",
    "\n",
    "print(\"\\nTopics for news in LDA model:\")\n",
    "print_top_words(lda, feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 20s, sys: 11.1 s, total: 7min 31s\n",
      "Wall time: 9min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "577.3352110385895"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#apply most similar topic to each document\n",
    "t0 = time.time()\n",
    "newsdf['lda_topics'] = np.ma.apply_along_axis(topic_sim, axis=1, \n",
    "        arr=tfidf_dm.toarray(), feature_names=tfidf.get_feature_names(), n_top_words=4, topics=lda.components_)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year like team game                      1978\n",
       "republican state government obama        1745\n",
       "school like year bar                       43\n",
       "building buildings street apartment        42\n",
       "children dr child school                   12\n",
       "city mayor people says                      8\n",
       "city air rights people                      6\n",
       "american police intelligence security       5\n",
       "company north french women                  3\n",
       "mayor year games children                   2\n",
       "teams research report defense               2\n",
       "minister prime private president            1\n",
       "republican senate vote house                1\n",
       "Name: lda_topics, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsdf['lda_topics'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>topics_20_5</th>\n",
       "      <th>lda_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ending a climactic showdown in the final hours of the 112th Congress, the House sent to President Obama legislation to avert big income tax increases on most Americans.</td>\n",
       "      <td>republican senate democrats senator house</td>\n",
       "      <td>republican state government obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A report on nearly three million people found that those whose body mass index ranked them as overweight had less risk of dying than people of normal weight.</td>\n",
       "      <td>dr study medical research university</td>\n",
       "      <td>year like team game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As the United States prepares to withdraw from an unpopular war in Afghanistan, it faces challenges similar to what the country’s last occupier, the Soviet Union, had experienced.</td>\n",
       "      <td>military government american weapons officials</td>\n",
       "      <td>republican state government obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The popularity of the drinks reflects success in convincing consumers that they provide an edge, but most of their ingredients have no or little benefit, research shows.</td>\n",
       "      <td>dr study medical research university</td>\n",
       "      <td>republican state government obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Hampshire, which again chose a woman to be governor, will also become the first state in history to have an all-female delegation in Washington.</td>\n",
       "      <td>women men woman sex book</td>\n",
       "      <td>republican state government obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>For a 65th birthday, a first burial pitch.</td>\n",
       "      <td>like don just people think</td>\n",
       "      <td>year like team game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The United Nations’ human rights chief, Navi Pillay, on Wednesday voiced dismay over an analysis that far exceeds earlier estimates of the toll in 22-month-old war.</td>\n",
       "      <td>military government american weapons officials</td>\n",
       "      <td>republican state government obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The depth of the anger that followed the House’s refusal to take up a package of assistance for Hurricane Sandy victims was extraordinary and exceedingly personal.</td>\n",
       "      <td>republican senate democrats senator house</td>\n",
       "      <td>republican state government obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How the breakout star (and daughter of David) turned “Girls” from a show about a trio to one about a quartet.</td>\n",
       "      <td>like don just people think</td>\n",
       "      <td>year like team game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Three memorable television characters who dressed for success (and sometimes to excess).</td>\n",
       "      <td>women men woman sex book</td>\n",
       "      <td>year like team game</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                           description  \\\n",
       "0             Ending a climactic showdown in the final hours of the 112th Congress, the House sent to President Obama legislation to avert big income tax increases on most Americans.   \n",
       "1                        A report on nearly three million people found that those whose body mass index ranked them as overweight had less risk of dying than people of normal weight.   \n",
       "2  As the United States prepares to withdraw from an unpopular war in Afghanistan, it faces challenges similar to what the country’s last occupier, the Soviet Union, had experienced.   \n",
       "3            The popularity of the drinks reflects success in convincing consumers that they provide an edge, but most of their ingredients have no or little benefit, research shows.   \n",
       "4                                 New Hampshire, which again chose a woman to be governor, will also become the first state in history to have an all-female delegation in Washington.   \n",
       "5                                                                                                                                           For a 65th birthday, a first burial pitch.   \n",
       "6                 The United Nations’ human rights chief, Navi Pillay, on Wednesday voiced dismay over an analysis that far exceeds earlier estimates of the toll in 22-month-old war.   \n",
       "7                  The depth of the anger that followed the House’s refusal to take up a package of assistance for Hurricane Sandy victims was extraordinary and exceedingly personal.   \n",
       "8                                                                        How the breakout star (and daughter of David) turned “Girls” from a show about a trio to one about a quartet.   \n",
       "9                                                                                             Three memorable television characters who dressed for success (and sometimes to excess).   \n",
       "\n",
       "                                      topics_20_5  \\\n",
       "0       republican senate democrats senator house   \n",
       "1            dr study medical research university   \n",
       "2  military government american weapons officials   \n",
       "3            dr study medical research university   \n",
       "4                        women men woman sex book   \n",
       "5                      like don just people think   \n",
       "6  military government american weapons officials   \n",
       "7       republican senate democrats senator house   \n",
       "8                      like don just people think   \n",
       "9                        women men woman sex book   \n",
       "\n",
       "                          lda_topics  \n",
       "0  republican state government obama  \n",
       "1                year like team game  \n",
       "2  republican state government obama  \n",
       "3  republican state government obama  \n",
       "4  republican state government obama  \n",
       "5                year like team game  \n",
       "6  republican state government obama  \n",
       "7  republican state government obama  \n",
       "8                year like team game  \n",
       "9                year like team game  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsdf[['description','topics_20_5','lda_topics']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Singular value decomposition and LSA\n",
    "\n",
    "####  LSA code and diagrams borrowed from Will Stanton (with many thanks): http://www.williamgstanton.com/ - unfortunately, the slides have disappeared from his website.\n",
    "\n",
    "Other suggested reading:\n",
    "* http://lsa.colorado.edu/papers/dp1.LSAintro.pdf\n",
    "* http://mccormickml.com/2016/03/25/lsa-for-text-classification-tutorial/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, SVD is a dimensionality reduction technique similar to PCA.  Here we use it to reduce the feature space (get rid of zeros similar to the NMF) and then extract \"important\" pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LSA. Use algorithm = “randomized” for large datasets\n",
    "# apply to our text examples again\n",
    "\n",
    "lsa = TruncatedSVD(3, algorithm = 'arpack')\n",
    "cvnorm_lsa = lsa.fit_transform(cvnorm_dm)\n",
    "cvnorm_lsa = Normalizer(copy=False).fit_transform(cvnorm_lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each LSA component is a linear combination of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>data</th>\n",
       "      <th>football</th>\n",
       "      <th>fun</th>\n",
       "      <th>great</th>\n",
       "      <th>learning</th>\n",
       "      <th>like</th>\n",
       "      <th>machine</th>\n",
       "      <th>python</th>\n",
       "      <th>science</th>\n",
       "      <th>statistics</th>\n",
       "      <th>super</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>component_1</th>\n",
       "      <td>0.205953</td>\n",
       "      <td>0.083666</td>\n",
       "      <td>0.136799</td>\n",
       "      <td>0.392147</td>\n",
       "      <td>0.274684</td>\n",
       "      <td>0.411709</td>\n",
       "      <td>0.049008</td>\n",
       "      <td>0.411709</td>\n",
       "      <td>0.319064</td>\n",
       "      <td>0.083666</td>\n",
       "      <td>0.073782</td>\n",
       "      <td>0.489158</td>\n",
       "      <td>0.087791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_2</th>\n",
       "      <td>-0.143532</td>\n",
       "      <td>-0.059996</td>\n",
       "      <td>0.698419</td>\n",
       "      <td>-0.198971</td>\n",
       "      <td>0.384218</td>\n",
       "      <td>-0.021209</td>\n",
       "      <td>0.371972</td>\n",
       "      <td>-0.021209</td>\n",
       "      <td>-0.009318</td>\n",
       "      <td>-0.059996</td>\n",
       "      <td>-0.076444</td>\n",
       "      <td>-0.213156</td>\n",
       "      <td>0.326448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_3</th>\n",
       "      <td>0.621099</td>\n",
       "      <td>-0.183674</td>\n",
       "      <td>0.056415</td>\n",
       "      <td>-0.474265</td>\n",
       "      <td>-0.015689</td>\n",
       "      <td>-0.138379</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>-0.138379</td>\n",
       "      <td>0.142182</td>\n",
       "      <td>-0.183674</td>\n",
       "      <td>0.447455</td>\n",
       "      <td>0.240370</td>\n",
       "      <td>0.015772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cool      data  football       fun     great  learning  \\\n",
       "component_1  0.205953  0.083666  0.136799  0.392147  0.274684  0.411709   \n",
       "component_2 -0.143532 -0.059996  0.698419 -0.198971  0.384218 -0.021209   \n",
       "component_3  0.621099 -0.183674  0.056415 -0.474265 -0.015689 -0.138379   \n",
       "\n",
       "                 like   machine    python   science  statistics     super  \\\n",
       "component_1  0.049008  0.411709  0.319064  0.083666    0.073782  0.489158   \n",
       "component_2  0.371972 -0.021209 -0.009318 -0.059996   -0.076444 -0.213156   \n",
       "component_3  0.040643 -0.138379  0.142182 -0.183674    0.447455  0.240370   \n",
       "\n",
       "                watch  \n",
       "component_1  0.087791  \n",
       "component_2  0.326448  \n",
       "component_3  0.015772  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lsa.components_,index = [\"component_1\",\"component_2\",\"component_3\"],columns = cvnorm.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each document is a linear combination of the LSA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "      <th>component_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Machine learning is super fun</th>\n",
       "      <td>0.928146</td>\n",
       "      <td>-0.247480</td>\n",
       "      <td>-0.278028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python is super, super cool</th>\n",
       "      <td>0.738578</td>\n",
       "      <td>-0.284539</td>\n",
       "      <td>0.611180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistics is cool, too</th>\n",
       "      <td>0.248376</td>\n",
       "      <td>-0.195317</td>\n",
       "      <td>0.948768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fun? Data science is more than fun</th>\n",
       "      <td>0.558296</td>\n",
       "      <td>-0.303859</td>\n",
       "      <td>-0.771994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python is great for machine learning</th>\n",
       "      <td>0.968419</td>\n",
       "      <td>0.227201</td>\n",
       "      <td>-0.102684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like football</th>\n",
       "      <td>0.170351</td>\n",
       "      <td>0.981357</td>\n",
       "      <td>0.088985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Football is great to watch</th>\n",
       "      <td>0.333741</td>\n",
       "      <td>0.941908</td>\n",
       "      <td>0.037766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      component_1  component_2  component_3\n",
       "Machine learning is super fun            0.928146    -0.247480    -0.278028\n",
       "Python is super, super cool              0.738578    -0.284539     0.611180\n",
       "Statistics is cool, too                  0.248376    -0.195317     0.948768\n",
       "Fun? Data science is more than fun       0.558296    -0.303859    -0.771994\n",
       "Python is great for machine learning     0.968419     0.227201    -0.102684\n",
       "I like football                          0.170351     0.981357     0.088985\n",
       "Football is great to watch               0.333741     0.941908     0.037766"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cvnorm_lsa, index = textStr, columns = [\"component_1\",\"component_2\",\"component_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9281456333640472,\n",
       "  0.7385777114863382,\n",
       "  0.24837620403530086,\n",
       "  0.5582961773012041,\n",
       "  0.9684191697560601,\n",
       "  0.17035099239586765,\n",
       "  0.3337414717255542],\n",
       " [-0.24747973299406437,\n",
       "  -0.28453856431053604,\n",
       "  -0.1953166236526416,\n",
       "  -0.3038592430937842,\n",
       "  0.2272010915726264,\n",
       "  0.9813573449925506,\n",
       "  0.9419078180327609])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = [w[0] for w in cvnorm_lsa]\n",
    "ys = [w[1] for w in cvnorm_lsa]\n",
    "xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Document similarity using LSA\n",
    "\n",
    "https://technowiki.wordpress.com/2011/08/27/latent-semantic-analysis-lsa-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Machine learning is super fun</th>\n",
       "      <th>Python is super, super cool</th>\n",
       "      <th>Statistics is cool, too</th>\n",
       "      <th>Fun? Data science is more than fun</th>\n",
       "      <th>Python is great for machine learning</th>\n",
       "      <th>I like football</th>\n",
       "      <th>Football is great to watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Machine learning is super fun</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586000</td>\n",
       "      <td>0.015082</td>\n",
       "      <td>0.808015</td>\n",
       "      <td>0.871155</td>\n",
       "      <td>-0.109496</td>\n",
       "      <td>0.066158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python is super, super cool</th>\n",
       "      <td>0.586000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818888</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.587847</td>\n",
       "      <td>-0.099031</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistics is cool, too</th>\n",
       "      <td>0.015082</td>\n",
       "      <td>0.818888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.534427</td>\n",
       "      <td>0.098733</td>\n",
       "      <td>-0.064938</td>\n",
       "      <td>-0.065245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fun? Data science is more than fun</th>\n",
       "      <td>0.808015</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>-0.534427</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.550899</td>\n",
       "      <td>-0.271784</td>\n",
       "      <td>-0.129036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python is great for machine learning</th>\n",
       "      <td>0.871155</td>\n",
       "      <td>0.587847</td>\n",
       "      <td>0.098733</td>\n",
       "      <td>0.550899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.378799</td>\n",
       "      <td>0.533326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like football</th>\n",
       "      <td>-0.109496</td>\n",
       "      <td>-0.099031</td>\n",
       "      <td>-0.064938</td>\n",
       "      <td>-0.271784</td>\n",
       "      <td>0.378799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Football is great to watch</th>\n",
       "      <td>0.066158</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>-0.065245</td>\n",
       "      <td>-0.129036</td>\n",
       "      <td>0.533326</td>\n",
       "      <td>0.984562</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Machine learning is super fun  \\\n",
       "Machine learning is super fun                              1.000000   \n",
       "Python is super, super cool                                0.586000   \n",
       "Statistics is cool, too                                    0.015082   \n",
       "Fun? Data science is more than fun                         0.808015   \n",
       "Python is great for machine learning                       0.871155   \n",
       "I like football                                           -0.109496   \n",
       "Football is great to watch                                 0.066158   \n",
       "\n",
       "                                      Python is super, super cool  \\\n",
       "Machine learning is super fun                            0.586000   \n",
       "Python is super, super cool                              1.000000   \n",
       "Statistics is cool, too                                  0.818888   \n",
       "Fun? Data science is more than fun                       0.026978   \n",
       "Python is great for machine learning                     0.587847   \n",
       "I like football                                         -0.099031   \n",
       "Football is great to watch                               0.001567   \n",
       "\n",
       "                                      Statistics is cool, too  \\\n",
       "Machine learning is super fun                        0.015082   \n",
       "Python is super, super cool                          0.818888   \n",
       "Statistics is cool, too                              1.000000   \n",
       "Fun? Data science is more than fun                  -0.534427   \n",
       "Python is great for machine learning                 0.098733   \n",
       "I like football                                     -0.064938   \n",
       "Football is great to watch                          -0.065245   \n",
       "\n",
       "                                      Fun? Data science is more than fun  \\\n",
       "Machine learning is super fun                                   0.808015   \n",
       "Python is super, super cool                                     0.026978   \n",
       "Statistics is cool, too                                        -0.534427   \n",
       "Fun? Data science is more than fun                              1.000000   \n",
       "Python is great for machine learning                            0.550899   \n",
       "I like football                                                -0.271784   \n",
       "Football is great to watch                                     -0.129036   \n",
       "\n",
       "                                      Python is great for machine learning  \\\n",
       "Machine learning is super fun                                     0.871155   \n",
       "Python is super, super cool                                       0.587847   \n",
       "Statistics is cool, too                                           0.098733   \n",
       "Fun? Data science is more than fun                                0.550899   \n",
       "Python is great for machine learning                              1.000000   \n",
       "I like football                                                   0.378799   \n",
       "Football is great to watch                                        0.533326   \n",
       "\n",
       "                                      I like football  \\\n",
       "Machine learning is super fun               -0.109496   \n",
       "Python is super, super cool                 -0.099031   \n",
       "Statistics is cool, too                     -0.064938   \n",
       "Fun? Data science is more than fun          -0.271784   \n",
       "Python is great for machine learning         0.378799   \n",
       "I like football                              1.000000   \n",
       "Football is great to watch                   0.984562   \n",
       "\n",
       "                                      Football is great to watch  \n",
       "Machine learning is super fun                           0.066158  \n",
       "Python is super, super cool                             0.001567  \n",
       "Statistics is cool, too                                -0.065245  \n",
       "Fun? Data science is more than fun                     -0.129036  \n",
       "Python is great for machine learning                    0.533326  \n",
       "I like football                                         0.984562  \n",
       "Football is great to watch                              1.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute document similarity using LSA components\n",
    "similarity = np.asarray(numpy.asmatrix(cvnorm_lsa) * numpy.asmatrix(cvnorm_lsa).T)\n",
    "pd.DataFrame(similarity,index=textStr, columns=textStr).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics for texts in LSA model:\n",
      "Topic #0:\n",
      "super machine\n",
      "Topic #1:\n",
      "football great\n",
      "Topic #2:\n",
      "cool statistics\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# back to our regularly scheduled feature - use LSA for topic extraction\n",
    "\n",
    "feature_names = names_texts\n",
    "n_top_words = 2\n",
    "\n",
    "print(\"\\nTopics for texts in LSA model:\")\n",
    "print_top_words(lsa, feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>nmf_topics</th>\n",
       "      <th>lda_topics</th>\n",
       "      <th>lsa_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine learning is super fun</td>\n",
       "      <td>fun machine</td>\n",
       "      <td>watch super</td>\n",
       "      <td>super machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python is super, super cool</td>\n",
       "      <td>cool statistics</td>\n",
       "      <td>cool football</td>\n",
       "      <td>super machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Statistics is cool, too</td>\n",
       "      <td>cool statistics</td>\n",
       "      <td>cool football</td>\n",
       "      <td>cool statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fun? Data science is more than fun</td>\n",
       "      <td>fun machine</td>\n",
       "      <td>fun data</td>\n",
       "      <td>super machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python is great for machine learning</td>\n",
       "      <td>fun machine</td>\n",
       "      <td>fun data</td>\n",
       "      <td>super machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I like football</td>\n",
       "      <td>football like</td>\n",
       "      <td>cool football</td>\n",
       "      <td>football great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Football is great to watch</td>\n",
       "      <td>football like</td>\n",
       "      <td>watch super</td>\n",
       "      <td>football great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text       nmf_topics     lda_topics  \\\n",
       "0         Machine learning is super fun      fun machine    watch super   \n",
       "1           Python is super, super cool  cool statistics  cool football   \n",
       "2               Statistics is cool, too  cool statistics  cool football   \n",
       "3    Fun? Data science is more than fun      fun machine       fun data   \n",
       "4  Python is great for machine learning      fun machine       fun data   \n",
       "5                       I like football    football like  cool football   \n",
       "6            Football is great to watch    football like    watch super   \n",
       "\n",
       "        lsa_topics  \n",
       "0    super machine  \n",
       "1    super machine  \n",
       "2  cool statistics  \n",
       "3    super machine  \n",
       "4    super machine  \n",
       "5   football great  \n",
       "6   football great  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's add these topic labels to our dataframe\n",
    "\n",
    "textdf['lsa_topics'] = np.ma.apply_along_axis(topic_sim, axis=1, \n",
    "        arr=cvnorm_dm.toarray(), feature_names=cvnorm.get_feature_names(), n_top_words=2, topics=lsa.components_)\n",
    "textdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's try it on our news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 20\n",
    "n_top_words = 5\n",
    "\n",
    "# Fit LSA. Use algorithm = “randomized” for large datasets\n",
    "lsa = TruncatedSVD(n_topics, algorithm = 'randomized')\n",
    "tfidf_lsa = lsa.fit_transform(tfidf_dm)\n",
    "tfidf_lsa = Normalizer(copy=False).fit_transform(tfidf_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics for news in LSA model:\n",
      "Topic #0:\n",
      "year like people city new\n",
      "Topic #1:\n",
      "republican obama senate government president\n",
      "Topic #2:\n",
      "game team season players games\n",
      "Topic #3:\n",
      "republican senate democrats house senator\n",
      "Topic #4:\n",
      "health company percent state insurance\n",
      "Topic #5:\n",
      "city mayor police ny school\n",
      "Topic #6:\n",
      "school students court state children\n",
      "Topic #7:\n",
      "school students education percent college\n",
      "Topic #8:\n",
      "health insurance care city obama\n",
      "Topic #9:\n",
      "dr women study research medical\n",
      "Topic #10:\n",
      "state china country military percent\n",
      "Topic #11:\n",
      "food oil state court obama\n",
      "Topic #12:\n",
      "building house street dr apartment\n",
      "Topic #13:\n",
      "police food officers government oil\n",
      "Topic #14:\n",
      "percent police food tax economy\n",
      "Topic #15:\n",
      "women police men students military\n",
      "Topic #16:\n",
      "women food company usa china\n",
      "Topic #17:\n",
      "china obama police president white\n",
      "Topic #18:\n",
      "state intelligence china american usa\n",
      "Topic #19:\n",
      "state china players obama police\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_names = tfidf.get_feature_names()\n",
    "\n",
    "print(\"\\nTopics for news in LSA model:\")\n",
    "print_top_words(lsa, feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537.5284647941589"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply most similar topic to each document\n",
    "t0 = time.time()\n",
    "newsdf['lsa_topics'] = np.ma.apply_along_axis(topic_sim, axis=1, \n",
    "        arr=tfidf_dm.toarray(), feature_names=names_news, n_top_words=5, topics=lsa.components_)\n",
    "t1 = time.time()\n",
    "\n",
    "t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year like people city new                       3071\n",
       "game team season players games                   189\n",
       "republican obama senate government president     122\n",
       "city mayor police ny school                       71\n",
       "republican senate democrats house senator         62\n",
       "dr women study research medical                   56\n",
       "school students education percent college         48\n",
       "health insurance care city obama                  48\n",
       "food oil state court obama                        48\n",
       "school students court state children              36\n",
       "women police men students military                23\n",
       "building house street dr apartment                21\n",
       "china obama police president white                11\n",
       "health company percent state insurance            10\n",
       "police food officers government oil                8\n",
       "state intelligence china american usa              7\n",
       "percent police food tax economy                    6\n",
       "state china country military percent               5\n",
       "women food company usa china                       4\n",
       "state china players obama police                   2\n",
       "Name: lsa_topics, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsdf['lsa_topics'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>topics_20_5</th>\n",
       "      <th>lda_topics</th>\n",
       "      <th>lsa_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ending a climactic showdown in the final hours of the 112th Congress, the House sent to President Obama legislation to avert big income tax increases on most Americans.</td>\n",
       "      <td>republican senate democrats senator house</td>\n",
       "      <td>republican state government obama</td>\n",
       "      <td>republican senate democrats house senator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A report on nearly three million people found that those whose body mass index ranked them as overweight had less risk of dying than people of normal weight.</td>\n",
       "      <td>dr study medical research university</td>\n",
       "      <td>year like team game</td>\n",
       "      <td>dr women study research medical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As the United States prepares to withdraw from an unpopular war in Afghanistan, it faces challenges similar to what the country’s last occupier, the Soviet Union, had experienced.</td>\n",
       "      <td>military government american weapons officials</td>\n",
       "      <td>republican state government obama</td>\n",
       "      <td>year like people city new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The popularity of the drinks reflects success in convincing consumers that they provide an edge, but most of their ingredients have no or little benefit, research shows.</td>\n",
       "      <td>dr study medical research university</td>\n",
       "      <td>republican state government obama</td>\n",
       "      <td>year like people city new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Hampshire, which again chose a woman to be governor, will also become the first state in history to have an all-female delegation in Washington.</td>\n",
       "      <td>women men woman sex book</td>\n",
       "      <td>republican state government obama</td>\n",
       "      <td>women police men students military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>For a 65th birthday, a first burial pitch.</td>\n",
       "      <td>like don just people think</td>\n",
       "      <td>year like team game</td>\n",
       "      <td>year like people city new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The United Nations’ human rights chief, Navi Pillay, on Wednesday voiced dismay over an analysis that far exceeds earlier estimates of the toll in 22-month-old war.</td>\n",
       "      <td>military government american weapons officials</td>\n",
       "      <td>republican state government obama</td>\n",
       "      <td>year like people city new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The depth of the anger that followed the House’s refusal to take up a package of assistance for Hurricane Sandy victims was extraordinary and exceedingly personal.</td>\n",
       "      <td>republican senate democrats senator house</td>\n",
       "      <td>republican state government obama</td>\n",
       "      <td>republican senate democrats house senator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How the breakout star (and daughter of David) turned “Girls” from a show about a trio to one about a quartet.</td>\n",
       "      <td>like don just people think</td>\n",
       "      <td>year like team game</td>\n",
       "      <td>year like people city new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Three memorable television characters who dressed for success (and sometimes to excess).</td>\n",
       "      <td>women men woman sex book</td>\n",
       "      <td>year like team game</td>\n",
       "      <td>women police men students military</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                           description  \\\n",
       "0             Ending a climactic showdown in the final hours of the 112th Congress, the House sent to President Obama legislation to avert big income tax increases on most Americans.   \n",
       "1                        A report on nearly three million people found that those whose body mass index ranked them as overweight had less risk of dying than people of normal weight.   \n",
       "2  As the United States prepares to withdraw from an unpopular war in Afghanistan, it faces challenges similar to what the country’s last occupier, the Soviet Union, had experienced.   \n",
       "3            The popularity of the drinks reflects success in convincing consumers that they provide an edge, but most of their ingredients have no or little benefit, research shows.   \n",
       "4                                 New Hampshire, which again chose a woman to be governor, will also become the first state in history to have an all-female delegation in Washington.   \n",
       "5                                                                                                                                           For a 65th birthday, a first burial pitch.   \n",
       "6                 The United Nations’ human rights chief, Navi Pillay, on Wednesday voiced dismay over an analysis that far exceeds earlier estimates of the toll in 22-month-old war.   \n",
       "7                  The depth of the anger that followed the House’s refusal to take up a package of assistance for Hurricane Sandy victims was extraordinary and exceedingly personal.   \n",
       "8                                                                        How the breakout star (and daughter of David) turned “Girls” from a show about a trio to one about a quartet.   \n",
       "9                                                                                             Three memorable television characters who dressed for success (and sometimes to excess).   \n",
       "\n",
       "                                      topics_20_5  \\\n",
       "0       republican senate democrats senator house   \n",
       "1            dr study medical research university   \n",
       "2  military government american weapons officials   \n",
       "3            dr study medical research university   \n",
       "4                        women men woman sex book   \n",
       "5                      like don just people think   \n",
       "6  military government american weapons officials   \n",
       "7       republican senate democrats senator house   \n",
       "8                      like don just people think   \n",
       "9                        women men woman sex book   \n",
       "\n",
       "                          lda_topics  \\\n",
       "0  republican state government obama   \n",
       "1                year like team game   \n",
       "2  republican state government obama   \n",
       "3  republican state government obama   \n",
       "4  republican state government obama   \n",
       "5                year like team game   \n",
       "6  republican state government obama   \n",
       "7  republican state government obama   \n",
       "8                year like team game   \n",
       "9                year like team game   \n",
       "\n",
       "                                  lsa_topics  \n",
       "0  republican senate democrats house senator  \n",
       "1            dr women study research medical  \n",
       "2                  year like people city new  \n",
       "3                  year like people city new  \n",
       "4         women police men students military  \n",
       "5                  year like people city new  \n",
       "6                  year like people city new  \n",
       "7  republican senate democrats house senator  \n",
       "8                  year like people city new  \n",
       "9         women police men students military  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsdf[['description','topics_20_5','lda_topics','lsa_topics']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some comparisons:\n",
    "* http://scikit-learn.org/0.17/auto_examples/applications/topics_extraction_with_nmf_lda.html\n",
    "* https://medium.com/@aneesha/topic-modeling-with-scikit-learn-e80d33668730\n",
    "* http://aclweb.org/anthology/D/D12/D12-1087.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6103896103896104\n",
      "accuracy: 0.6103896103896104\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "      building street apartment park buildings       0.50      0.53      0.51        59\n",
      "               china usa party north countries       0.75      0.75      0.75        24\n",
      "               city mayor ny campaign brooklyn       0.56      0.54      0.55        46\n",
      "  company data industry technology information       0.61      0.61      0.61        74\n",
      "                  court justice judge case law       0.53      0.65      0.59        26\n",
      "          dr study medical research university       0.55      0.53      0.54        34\n",
      "                 food oil water add restaurant       0.64      0.62      0.63        52\n",
      "                   game team games season play       0.75      0.68      0.71        87\n",
      "               health insurance care law plans       0.71      0.69      0.70        32\n",
      "                    like don just people think       0.64      0.62      0.63       232\n",
      "military government american weapons officials       0.67      0.70      0.68        86\n",
      "         mother family father children parents       0.36      0.50      0.42        42\n",
      "    obama president administration white house       0.55      0.58      0.57        48\n",
      "               percent market tax year economy       0.40      0.33      0.36        58\n",
      "             players league season player team       0.58      0.75      0.65        44\n",
      "  police officers department crime enforcement       0.62      0.71      0.67        35\n",
      "     republican senate democrats senator house       0.71      0.68      0.70        76\n",
      "     school students education college student       0.83      0.48      0.61        42\n",
      "                 state new jersey laws federal       0.56      0.56      0.56        32\n",
      "                      women men woman sex book       0.63      0.65      0.64        26\n",
      "\n",
      "                                      accuracy                           0.61      1155\n",
      "                                     macro avg       0.61      0.61      0.60      1155\n",
      "                                  weighted avg       0.62      0.61      0.61      1155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# can we predict the topic labels?\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = tfidf_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "y = newsdf['topics_20_5'].values #this is an array of labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #random_state is set seed\n",
    "\n",
    "# Decision Tree Classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier(random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_test\n",
    "clf1_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8199134199134199\n",
      "accuracy: 0.8199134199134199\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "american police intelligence security       0.00      0.00      0.00         0\n",
      "  building buildings street apartment       0.00      0.00      0.00        14\n",
      "             children dr child school       0.00      0.00      0.00         4\n",
      "               city air rights people       0.00      0.00      0.00         1\n",
      "               city mayor people says       0.00      0.00      0.00         3\n",
      "           company north french women       0.00      0.00      0.00         1\n",
      "    republican state government obama       0.83      0.84      0.84       527\n",
      "                 school like year bar       0.09      0.08      0.08        13\n",
      "        teams research report defense       0.00      0.00      0.00         1\n",
      "                  year like team game       0.84      0.85      0.85       591\n",
      "\n",
      "                             accuracy                           0.82      1155\n",
      "                            macro avg       0.18      0.18      0.18      1155\n",
      "                         weighted avg       0.81      0.82      0.82      1155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scannon3/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/scannon3/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# can we predict the topic labels?\n",
    "\n",
    "X = tfidf_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "y = newsdf['lda_topics'].values #this is an array of labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #random_state is set seed\n",
    "\n",
    "# Decision Tree Classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier(random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_test\n",
    "clf1_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some comparisons:\n",
    "* http://scikit-learn.org/0.17/auto_examples/applications/topics_extraction_with_nmf_lda.html\n",
    "* https://medium.com/@aneesha/topic-modeling-with-scikit-learn-e80d33668730\n",
    "* http://aclweb.org/anthology/D/D12/D12-1087.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just for fun: how closely to topics and cluster assignment line up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.561550855636597"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "t0= time.time()\n",
    "news_dm = tfidf_dm.toarray()\n",
    "My_k = 20\n",
    "km = KMeans(n_clusters=My_k, init='k-means++', max_iter=100, random_state = 42)\n",
    "news_k = km.fit(news_dm)\n",
    "clusters = km.labels_.tolist()\n",
    "newsdf['clusters'] = clusters\n",
    "t1 = time.time()\n",
    "\n",
    "t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters:\n",
      "14    750\n",
      "10    402\n",
      "0     267\n",
      "16    259\n",
      "15    244\n",
      "8     205\n",
      "13    194\n",
      "11    167\n",
      "2     160\n",
      "1     155\n",
      "6     149\n",
      "5     145\n",
      "19    142\n",
      "4     124\n",
      "18    114\n",
      "7     106\n",
      "9     105\n",
      "12     56\n",
      "17     56\n",
      "3      48\n",
      "Name: clusters, dtype: int64\n",
      "\n",
      "NMF:\n",
      "like don just people think                        751\n",
      "military government american weapons officials    317\n",
      "game team games season play                       271\n",
      "republican senate democrats senator house         213\n",
      "company data industry technology information      209\n",
      "percent market tax year economy                   204\n",
      "building street apartment park buildings          198\n",
      "mother family father children parents             179\n",
      "food oil water add restaurant                     178\n",
      "city mayor ny campaign brooklyn                   175\n",
      "players league season player team                 150\n",
      "court justice judge case law                      141\n",
      "obama president administration white house        140\n",
      "dr study medical research university              139\n",
      "school students education college student         125\n",
      "health insurance care law plans                   116\n",
      "police officers department crime enforcement      111\n",
      "state new jersey laws federal                      93\n",
      "women men woman sex book                           70\n",
      "china usa party north countries                    68\n",
      "Name: topics_20_5, dtype: int64\n",
      "\n",
      "LDA:\n",
      "year like team game                      1978\n",
      "republican state government obama        1745\n",
      "school like year bar                       43\n",
      "building buildings street apartment        42\n",
      "children dr child school                   12\n",
      "city mayor people says                      8\n",
      "city air rights people                      6\n",
      "american police intelligence security       5\n",
      "company north french women                  3\n",
      "mayor year games children                   2\n",
      "teams research report defense               2\n",
      "minister prime private president            1\n",
      "republican senate vote house                1\n",
      "Name: lda_topics, dtype: int64\n",
      "\n",
      "LSA\n",
      "year like people city new                       3071\n",
      "game team season players games                   189\n",
      "republican obama senate government president     122\n",
      "city mayor police ny school                       71\n",
      "republican senate democrats house senator         62\n",
      "dr women study research medical                   56\n",
      "school students education percent college         48\n",
      "health insurance care city obama                  48\n",
      "food oil state court obama                        48\n",
      "school students court state children              36\n",
      "women police men students military                23\n",
      "building house street dr apartment                21\n",
      "china obama police president white                11\n",
      "health company percent state insurance            10\n",
      "police food officers government oil                8\n",
      "state intelligence china american usa              7\n",
      "percent police food tax economy                    6\n",
      "state china country military percent               5\n",
      "women food company usa china                       4\n",
      "state china players obama police                   2\n",
      "Name: lsa_topics, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Clusters:\")\n",
    "print(newsdf['clusters'].value_counts())\n",
    "print(\"\\nNMF:\")\n",
    "print(newsdf['topics_20_5'].value_counts())\n",
    "print(\"\\nLDA:\")\n",
    "print(newsdf['lda_topics'].value_counts())\n",
    "print(\"\\nLSA\")\n",
    "print(newsdf['lsa_topics'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>topics_20_5</th>\n",
       "      <th>lda_topics</th>\n",
       "      <th>lsa_topics</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Divided House Passes Tax Deal in End to Latest Fiscal Standoff</td>\n",
       "      <td>republican senate democrats senator house</td>\n",
       "      <td>republican state government obama</td>\n",
       "      <td>republican senate democrats house senator</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Study Suggests Lower Mortality Risk for People Deemed to Be Overweight</td>\n",
       "      <td>dr study medical research university</td>\n",
       "      <td>year like team game</td>\n",
       "      <td>dr women study research medical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With U.S. Set to Leave Afghanistan, Echoes of 1989</td>\n",
       "      <td>military government american weapons officials</td>\n",
       "      <td>republican state government obama</td>\n",
       "      <td>year like people city new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Energy Drinks Promise Edge, but Experts Say Proof Is Scant</td>\n",
       "      <td>dr study medical research university</td>\n",
       "      <td>republican state government obama</td>\n",
       "      <td>year like people city new</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From Congress to Halls of State, in New Hampshire, Women Rule</td>\n",
       "      <td>women men woman sex book</td>\n",
       "      <td>republican state government obama</td>\n",
       "      <td>women police men students military</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wanted: Mausoleum w/Wi-Fi, Cable, River Vu</td>\n",
       "      <td>like don just people think</td>\n",
       "      <td>year like team game</td>\n",
       "      <td>year like people city new</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>More Than 60,000 Have Died in Syrian Conflict, U.N. Says</td>\n",
       "      <td>military government american weapons officials</td>\n",
       "      <td>republican state government obama</td>\n",
       "      <td>year like people city new</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stalling of Storm Aid Makes Northeast Republicans Furious</td>\n",
       "      <td>republican senate democrats senator house</td>\n",
       "      <td>republican state government obama</td>\n",
       "      <td>republican senate democrats house senator</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zosia Mamet Is Still Getting Used to Being Your New Best Friend</td>\n",
       "      <td>like don just people think</td>\n",
       "      <td>year like team game</td>\n",
       "      <td>year like people city new</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>To Thine Own Character</td>\n",
       "      <td>women men woman sex book</td>\n",
       "      <td>year like team game</td>\n",
       "      <td>women police men students military</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 headline  \\\n",
       "0          Divided House Passes Tax Deal in End to Latest Fiscal Standoff   \n",
       "1  Study Suggests Lower Mortality Risk for People Deemed to Be Overweight   \n",
       "2                      With U.S. Set to Leave Afghanistan, Echoes of 1989   \n",
       "3              Energy Drinks Promise Edge, but Experts Say Proof Is Scant   \n",
       "4           From Congress to Halls of State, in New Hampshire, Women Rule   \n",
       "5                              Wanted: Mausoleum w/Wi-Fi, Cable, River Vu   \n",
       "6                More Than 60,000 Have Died in Syrian Conflict, U.N. Says   \n",
       "7               Stalling of Storm Aid Makes Northeast Republicans Furious   \n",
       "8         Zosia Mamet Is Still Getting Used to Being Your New Best Friend   \n",
       "9                                                  To Thine Own Character   \n",
       "\n",
       "                                      topics_20_5  \\\n",
       "0       republican senate democrats senator house   \n",
       "1            dr study medical research university   \n",
       "2  military government american weapons officials   \n",
       "3            dr study medical research university   \n",
       "4                        women men woman sex book   \n",
       "5                      like don just people think   \n",
       "6  military government american weapons officials   \n",
       "7       republican senate democrats senator house   \n",
       "8                      like don just people think   \n",
       "9                        women men woman sex book   \n",
       "\n",
       "                          lda_topics  \\\n",
       "0  republican state government obama   \n",
       "1                year like team game   \n",
       "2  republican state government obama   \n",
       "3  republican state government obama   \n",
       "4  republican state government obama   \n",
       "5                year like team game   \n",
       "6  republican state government obama   \n",
       "7  republican state government obama   \n",
       "8                year like team game   \n",
       "9                year like team game   \n",
       "\n",
       "                                  lsa_topics  clusters  \n",
       "0  republican senate democrats house senator        13  \n",
       "1            dr women study research medical         1  \n",
       "2                  year like people city new         0  \n",
       "3                  year like people city new         1  \n",
       "4         women police men students military         9  \n",
       "5                  year like people city new         6  \n",
       "6                  year like people city new         8  \n",
       "7  republican senate democrats house senator        13  \n",
       "8                  year like people city new        14  \n",
       "9         women police men students military        14  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsdf[['headline','topics_20_5','lda_topics','lsa_topics', 'clusters']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NMF:\n",
      "military government american weapons officials    138\n",
      "china usa party north countries                     9\n",
      "like don just people think                          8\n",
      "republican senate democrats senator house           7\n",
      "court justice judge case law                        7\n",
      "police officers department crime enforcement        7\n",
      "city mayor ny campaign brooklyn                     4\n",
      "percent market tax year economy                     4\n",
      "company data industry technology information        4\n",
      "building street apartment park buildings            3\n",
      "women men woman sex book                            3\n",
      "obama president administration white house          3\n",
      "state new jersey laws federal                       3\n",
      "mother family father children parents               3\n",
      "health insurance care law plans                     1\n",
      "food oil water add restaurant                       1\n",
      "Name: topics_20_5, dtype: int64\n",
      "\n",
      "LDA:\n",
      "republican state government obama        189\n",
      "year like team game                        5\n",
      "building buildings street apartment        3\n",
      "city mayor people says                     3\n",
      "american police intelligence security      2\n",
      "school like year bar                       1\n",
      "children dr child school                   1\n",
      "minister prime private president           1\n",
      "Name: lda_topics, dtype: int64\n",
      "\n",
      "LSA\n",
      "year like people city new                       202\n",
      "women police men students military                2\n",
      "republican obama senate government president      1\n",
      "Name: lsa_topics, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#what is the distribution of topics per cluster\n",
    "thing = newsdf.loc[newsdf['clusters'] == 8]\n",
    "print(\"\\nNMF:\")\n",
    "print(thing['topics_20_5'].value_counts())\n",
    "print(\"\\nLDA:\")\n",
    "print(thing['lda_topics'].value_counts())\n",
    "print(\"\\nLSA\")\n",
    "print(thing['lsa_topics'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main take aways:\n",
    "\n",
    "* More examples: https://medium.com/@aneesha/topic-modeling-with-scikit-learn-e80d33668730\n",
    "* Documents can be classified by topic using words that don't appear in that document (content vs expression!) \n",
    "* We learned 3 different methods for extracting topics \n",
    "* Number of topics and number of words used to describe a topic are decisions that data scientists make (along with classifier and settings choices, what external information to include (and how), label creation options (dictionary/index), preprocesing options (stop word lists, stemming/lemmatization), vectorizer options, parameter settings, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
