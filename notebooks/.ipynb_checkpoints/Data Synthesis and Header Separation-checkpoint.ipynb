{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indeed Scraping:\n",
    "\n",
    "Source: [Github](https://github.com/jlgamez/indeed-jobs-scraper)\n",
    "[Article](https://jlgamez.com/how-i-scrape-jobs-data-from-indeed-com-with-python/)\n",
    "\n",
    "[Article 2](https://www.jobspikr.com/blog/scraping-indeed-job-data-using-python/)\n",
    "\n",
    "### Final Data Fields:\n",
    "* Job Title\n",
    "* Summary\n",
    "* Location\n",
    "* Name of the Company\n",
    "* The Date posted\n",
    "* Details\n",
    "* Job URL\n",
    "\n",
    "\n",
    "I wrote a script to do all the scraping. In this notebook, we focus on the data processing, and EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions\n",
      "Pandas: 1.2.1\n",
      "Numpy: 1.19.2\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "## All my imports\n",
    "print(\"Versions\")\n",
    "# Data science\n",
    "import pandas as pd\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "import numpy as np\n",
    "print(f\"Numpy: {np.__version__}\")\n",
    "# Visualization \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "import os\n",
    "# Text Stuff\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion and Wrangling (ETL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>details</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>Data Scientist\\n\\nChange Research is innovatin...</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>We offer competitive salaries, plus a flexible...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=7d2b790d1b5b...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 days ago</td>\n",
       "      <td>Key skills required for the job are: n Data Sc...</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>You should be able to prepare a road map for t...</td>\n",
       "      <td>Data Science-Consultant</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=bb70ab1cb5cb...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>This role applies skills as a seasoned, experi...</td>\n",
       "      <td>San Francisco, CA 94143 (Haight-Ashbury area)</td>\n",
       "      <td>Experience working with other data scientists,...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=11c99adb5fa6...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 days ago</td>\n",
       "      <td>Position Overview:\\nThe Climate Corporation’s ...</td>\n",
       "      <td>San Francisco, CA 94103 (Yerba Buena area)</td>\n",
       "      <td>Accelerate data science innovation and adoptio...</td>\n",
       "      <td>Intern: Data Scientist</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=07fcf3dd80ab...</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just posted</td>\n",
       "      <td>eBay Inc. is a global commerce leader that con...</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>In addition to delivering insights on existing...</td>\n",
       "      <td>Ads Data Scientist</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=1dbac99ba3bd...</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>*Overview*We are seeking a Principal Data Scie...</td>\n",
       "      <td>San Mateo, CA</td>\n",
       "      <td>At the intersection of clinical, operational, ...</td>\n",
       "      <td>Principal Data Scientist (Machine Learning Pla...</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=1891e3d29cef...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Today</td>\n",
       "      <td>About Spin\\n\\nSpin is a fast-growing micromobi...</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Build, evolve, and scale state-of-the-art mach...</td>\n",
       "      <td>Staff Machine Learning Infrastructure Engineer</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=07bddc7e6d9b...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>18 days ago</td>\n",
       "      <td>Position Summary...\\nWhat you'll do...\\nWalmar...</td>\n",
       "      <td>San Bruno, CA 94066</td>\n",
       "      <td>We are seeking an experienced data science ind...</td>\n",
       "      <td>Staff Data Scientist - Walmart Connect</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=1bca654ed0a7...</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>27 days ago</td>\n",
       "      <td>Company Description\\n\\nCash App is the fastest...</td>\n",
       "      <td>San Francisco, CA 94103 (South of Market area)</td>\n",
       "      <td>15+ years of software development/machine lear...</td>\n",
       "      <td>Head of Applied Machine Learning Engineering, ...</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=345624f222bc...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>26 days ago</td>\n",
       "      <td>Become a Part of the NIKE, Inc. Team\\nNIKE, In...</td>\n",
       "      <td>San Francisco, CA 94108 (Downtown area)</td>\n",
       "      <td>You will use predictive analytics and machine ...</td>\n",
       "      <td>Principal, Machine Learning Scientist</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=4c0f2329aa17...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date                                            details  \\\n",
       "0    30+ days ago  Data Scientist\\n\\nChange Research is innovatin...   \n",
       "1      3 days ago  Key skills required for the job are: n Data Sc...   \n",
       "2    30+ days ago  This role applies skills as a seasoned, experi...   \n",
       "3      4 days ago  Position Overview:\\nThe Climate Corporation’s ...   \n",
       "4     Just posted  eBay Inc. is a global commerce leader that con...   \n",
       "..            ...                                                ...   \n",
       "365  30+ days ago  *Overview*We are seeking a Principal Data Scie...   \n",
       "366         Today  About Spin\\n\\nSpin is a fast-growing micromobi...   \n",
       "367   18 days ago  Position Summary...\\nWhat you'll do...\\nWalmar...   \n",
       "368   27 days ago  Company Description\\n\\nCash App is the fastest...   \n",
       "369   26 days ago  Become a Part of the NIKE, Inc. Team\\nNIKE, In...   \n",
       "\n",
       "                                           location  \\\n",
       "0                                 San Francisco, CA   \n",
       "1                                 San Francisco, CA   \n",
       "2     San Francisco, CA 94143 (Haight-Ashbury area)   \n",
       "3        San Francisco, CA 94103 (Yerba Buena area)   \n",
       "4                                 San Francisco, CA   \n",
       "..                                              ...   \n",
       "365                                   San Mateo, CA   \n",
       "366                               San Francisco, CA   \n",
       "367                             San Bruno, CA 94066   \n",
       "368  San Francisco, CA 94103 (South of Market area)   \n",
       "369         San Francisco, CA 94108 (Downtown area)   \n",
       "\n",
       "                                               summary  \\\n",
       "0    We offer competitive salaries, plus a flexible...   \n",
       "1    You should be able to prepare a road map for t...   \n",
       "2    Experience working with other data scientists,...   \n",
       "3    Accelerate data science innovation and adoptio...   \n",
       "4    In addition to delivering insights on existing...   \n",
       "..                                                 ...   \n",
       "365  At the intersection of clinical, operational, ...   \n",
       "366  Build, evolve, and scale state-of-the-art mach...   \n",
       "367  We are seeking an experienced data science ind...   \n",
       "368  15+ years of software development/machine lear...   \n",
       "369  You will use predictive analytics and machine ...   \n",
       "\n",
       "                                                 title  \\\n",
       "0                                       Data Scientist   \n",
       "1                              Data Science-Consultant   \n",
       "2                                       Data Scientist   \n",
       "3                               Intern: Data Scientist   \n",
       "4                                   Ads Data Scientist   \n",
       "..                                                 ...   \n",
       "365  Principal Data Scientist (Machine Learning Pla...   \n",
       "366     Staff Machine Learning Infrastructure Engineer   \n",
       "367             Staff Data Scientist - Walmart Connect   \n",
       "368  Head of Applied Machine Learning Engineering, ...   \n",
       "369              Principal, Machine Learning Scientist   \n",
       "\n",
       "                                                   url  rating  \n",
       "0    https://www.indeed.com/viewjob?jk=7d2b790d1b5b...     4.5  \n",
       "1    https://www.indeed.com/viewjob?jk=bb70ab1cb5cb...     3.8  \n",
       "2    https://www.indeed.com/viewjob?jk=11c99adb5fa6...     4.2  \n",
       "3    https://www.indeed.com/viewjob?jk=07fcf3dd80ab...     3.5  \n",
       "4    https://www.indeed.com/viewjob?jk=1dbac99ba3bd...     3.9  \n",
       "..                                                 ...     ...  \n",
       "365  https://www.indeed.com/viewjob?jk=1891e3d29cef...     NaN  \n",
       "366  https://www.indeed.com/viewjob?jk=07bddc7e6d9b...     3.0  \n",
       "367  https://www.indeed.com/viewjob?jk=1bca654ed0a7...     3.5  \n",
       "368  https://www.indeed.com/viewjob?jk=345624f222bc...     NaN  \n",
       "369  https://www.indeed.com/viewjob?jk=4c0f2329aa17...     4.1  \n",
       "\n",
       "[370 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed = pd.DataFrame(columns = ['date', 'details', 'location', 'summary', \n",
    "                                     'title', 'url', 'rating'])\n",
    "a = pd.read_json('../data/results/data.json2021-03-01 20:18 sfds')\n",
    "\n",
    "indeed = indeed.append(a)\n",
    "\n",
    "indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist\\n\\nChange Research is innovatin...</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science-Consultant</td>\n",
       "      <td>Key skills required for the job are: n Data Sc...</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>This role applies skills as a seasoned, experi...</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intern: Data Scientist</td>\n",
       "      <td>Position Overview:\\nThe Climate Corporation’s ...</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ads Data Scientist</td>\n",
       "      <td>eBay Inc. is a global commerce leader that con...</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Title                                        Description  \\\n",
       "0           Data Scientist  Data Scientist\\n\\nChange Research is innovatin...   \n",
       "1  Data Science-Consultant  Key skills required for the job are: n Data Sc...   \n",
       "2           Data Scientist  This role applies skills as a seasoned, experi...   \n",
       "3   Intern: Data Scientist  Position Overview:\\nThe Climate Corporation’s ...   \n",
       "4       Ads Data Scientist  eBay Inc. is a global commerce leader that con...   \n",
       "\n",
       "        Location  \n",
       "0  san francisco  \n",
       "1  san francisco  \n",
       "2  san francisco  \n",
       "3  san francisco  \n",
       "4  san francisco  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ingesting the data from the Indeed scraping\n",
    "\n",
    "\n",
    "def ingest_indeed(path = '../data/results/'):\n",
    "    ''' \n",
    "    Inputs: Path of the files where the scraped data (results from the indeed.py\n",
    "    goes to)   \n",
    "    \n",
    "    Outputs: The final indeed dataframe with just \"Title\", \"Description\", and \"Location\"\n",
    "    '''\n",
    "\n",
    "    indeed = pd.DataFrame(columns = ['date', 'details', 'location', 'summary', \n",
    "                                     'title', 'url', 'rating'])\n",
    "    \n",
    "    json_files = [i for i in os.listdir(path) if 'data.json' in i]\n",
    "    for file in json_files:\n",
    "        indeed = indeed.append(pd.read_json(path + file))\n",
    "\n",
    "    # Combining the Details and Summary section from the indeed into - also adding location \n",
    "    # ONE column\n",
    "    def combine(df):\n",
    "        ''' \n",
    "        Combining the details and summary section\n",
    "        Bonus: Attaching the location info\n",
    "        '''\n",
    "        location = []\n",
    "        full = []\n",
    "\n",
    "        for i, j, loc in zip(df['details'], df['summary'], df['location']):\n",
    "            full.append(i + '\\n' + j)\n",
    "\n",
    "            loc = loc.lower()\n",
    "\n",
    "            if \"san francisco\" in loc or \"sf\" in loc:\n",
    "                location.append(\"san francisco\")\n",
    "            elif \"new york\" in loc or \"ny\" in loc:\n",
    "                location.append(\"new york\")\n",
    "            elif \"texas\" in loc or \"tx\" in loc:\n",
    "                location.append(\"texas\")\n",
    "            else:\n",
    "                location.append(\"other\")\n",
    "\n",
    "        return pd.DataFrame({'Title': df['title'], 'Description': full, \n",
    "                            'Location': location})\n",
    "\n",
    "    # Narrowing down to the parts we want and updating the changes into the \n",
    "    # indeed object\n",
    "    indeed = combine(indeed)\n",
    "    \n",
    "    return indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist\\n\\nChange Research is innovatin...</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science-Consultant</td>\n",
       "      <td>Key skills required for the job are: n Data Sc...</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>This role applies skills as a seasoned, experi...</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intern: Data Scientist</td>\n",
       "      <td>Position Overview:\\nThe Climate Corporation’s ...</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ads Data Scientist</td>\n",
       "      <td>eBay Inc. is a global commerce leader that con...</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Title                                        Description  \\\n",
       "0           Data Scientist  Data Scientist\\n\\nChange Research is innovatin...   \n",
       "1  Data Science-Consultant  Key skills required for the job are: n Data Sc...   \n",
       "2           Data Scientist  This role applies skills as a seasoned, experi...   \n",
       "3   Intern: Data Scientist  Position Overview:\\nThe Climate Corporation’s ...   \n",
       "4       Ads Data Scientist  eBay Inc. is a global commerce leader that con...   \n",
       "\n",
       "        Location  \n",
       "0  san francisco  \n",
       "1  san francisco  \n",
       "2  san francisco  \n",
       "3  san francisco  \n",
       "4  san francisco  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed = ingest_indeed()\n",
    "indeed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new york         756\n",
       "san francisco    536\n",
       "texas            195\n",
       "other            183\n",
       "Name: Location, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed['Location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1670, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_linkedin(path = '../data/results/'):\n",
    "    '''\n",
    "    Ingesting the data from the LinkedIn scraping, and aggregating \n",
    "    them all to one dataframe\n",
    "    '''\n",
    "\n",
    "    linkedin = pd.DataFrame(columns = [\"Title\", \"Description\", \"Company Name\", \"Location\", \"Industry\", \n",
    "                                       \"Job Functions\", \"Time Posted\", \"Employment Type\", \"Applicant Count\"])\n",
    "\n",
    "    for file in [i for i in os.listdir(path) if 'job_scraping' in i]:\n",
    "        linkedin = linkedin.append(pd.read_csv(path + file))\n",
    "\n",
    "\n",
    "    # Location simplification\n",
    "    location = []\n",
    "    for loc in linkedin['Location']:\n",
    "\n",
    "        loc = loc.lower()\n",
    "\n",
    "        if \"san francisco\" in loc or \"sf\" in loc:\n",
    "            location.append(\"san francisco\")\n",
    "        elif \"new york\" in loc or \"ny\" in loc:\n",
    "            location.append(\"new york\")\n",
    "        elif \"texas\" in loc or \"tx\" in loc:\n",
    "            location.append(\"texas\")\n",
    "        else:\n",
    "            location.append(\"other\")\n",
    "\n",
    "    linkedin['Location'] = location\n",
    "\n",
    "    linkedin.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "    \n",
    "    return linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Job Functions</th>\n",
       "      <th>Time Posted</th>\n",
       "      <th>Employment Type</th>\n",
       "      <th>Applicant Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>\\n\\n\\nThis position can be based remotely anyw...</td>\n",
       "      <td>Linde</td>\n",
       "      <td>new york</td>\n",
       "      <td>Oil &amp; Energy</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>199 applicants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>\\n\\nSummary\\n \\nImagine what you could do here...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>texas</td>\n",
       "      <td>Consumer Electronics</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>12 applicants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>\\nLead analytics and measurement efforts for s...</td>\n",
       "      <td>Merkle</td>\n",
       "      <td>other</td>\n",
       "      <td>Marketing &amp; Advertising</td>\n",
       "      <td>Strategy/Planning</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>54 applicants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist, Product Analytics</td>\n",
       "      <td>\\nAbout Gusto\\n\\nGusto is a modern, online peo...</td>\n",
       "      <td>Gusto</td>\n",
       "      <td>other</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Internet</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>27 applicants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Search Data Scientist, Apple App Store - Austin</td>\n",
       "      <td>\\n\\nSummary\\n \\nAt Apple, new ideas have a way...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>texas</td>\n",
       "      <td>Consumer Electronics</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>7 applicants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Title  \\\n",
       "0                                   Data Scientist   \n",
       "1                                   Data Scientist   \n",
       "2                                   Data Scientist   \n",
       "3                Data Scientist, Product Analytics   \n",
       "4  Search Data Scientist, Apple App Store - Austin   \n",
       "\n",
       "                                         Description  \\\n",
       "0  \\n\\n\\nThis position can be based remotely anyw...   \n",
       "1  \\n\\nSummary\\n \\nImagine what you could do here...   \n",
       "2  \\nLead analytics and measurement efforts for s...   \n",
       "3  \\nAbout Gusto\\n\\nGusto is a modern, online peo...   \n",
       "4  \\n\\nSummary\\n \\nAt Apple, new ideas have a way...   \n",
       "\n",
       "                       Company Name  Location  \\\n",
       "0                 Linde              new york   \n",
       "1                 Apple                 texas   \n",
       "2                Merkle                 other   \n",
       "3                 Gusto                 other   \n",
       "4                 Apple                 texas   \n",
       "\n",
       "                                            Industry  \\\n",
       "0                           Oil & Energy               \n",
       "1                   Consumer Electronics               \n",
       "2                Marketing & Advertising               \n",
       "3                      Computer Software               \n",
       "4                   Consumer Electronics               \n",
       "\n",
       "                                      Job Functions  \\\n",
       "0                Information Technology               \n",
       "1                           Engineering               \n",
       "2                     Strategy/Planning               \n",
       "3                              Internet               \n",
       "4                           Engineering               \n",
       "\n",
       "                          Time Posted                     Employment Type  \\\n",
       "0               2 weeks ago                           Entry level           \n",
       "1              12 hours ago                               Full-time         \n",
       "2                5 days ago                      Mid-Senior level           \n",
       "3              21 hours ago                           Entry level           \n",
       "4              21 hours ago                               Full-time         \n",
       "\n",
       "                                    Applicant Count  \n",
       "0                    199 applicants                  \n",
       "1                     12 applicants                  \n",
       "2                     54 applicants                  \n",
       "3                     27 applicants                  \n",
       "4                      7 applicants                  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin = ingest_linkedin()\n",
    "\n",
    "linkedin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other            20\n",
       "texas             7\n",
       "new york          5\n",
       "san francisco     1\n",
       "Name: Location, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin['Location'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging\n",
    "Now we want to combine both the indeed and LinkedIn data into one dataframe containing very similar formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([linkedin[['Title', 'Description', 'Location']], indeed])\n",
    "merged['Title'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I add a label based on the job title\n",
    "titles = []\n",
    "for title in merged['Title']:\n",
    "    title = title.lower()\n",
    "    \n",
    "    if \"data analyst\" in title:\n",
    "        titles.append(\"data analyst\")\n",
    "    elif \"data scientist\" in title:\n",
    "        titles.append(\"data scientist\")\n",
    "    elif \"business analyst\" in title:\n",
    "        titles.append(\"business anlayst\")\n",
    "    elif \"machine learning\" in title:\n",
    "        titles.append(\"machine learning\")\n",
    "    elif \"data engineer\" in title:\n",
    "        titles.append(\"data engineer\")\n",
    "    else:\n",
    "        titles.append(\"other\")\n",
    "merged[\"Job Title\"] = titles\n",
    "merged.drop(\"Title\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Compare business intelligence analyst to data analyst? See if they look similar enough for us to put together. Same for MLE and DS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Wordcloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "# Combining entire description column into a single string\n",
    "\n",
    "def visualize_counts(data):\n",
    "    \n",
    "    # NLTK stopwords\n",
    "    stop = stopwords.words(\"english\") + [\"data\"]\n",
    "    # Manual stopwords\n",
    "    my_stop = [\"and\", \"to\", \"the\", \"of\", \"with\", \"data\"]\n",
    "    \n",
    "    combined_corpus = \"\"\n",
    "    for i in data[\"Description\"]:\n",
    "        combined_corpus += '\\n' + i\n",
    "\n",
    "    # Generate word cloud visualization\n",
    "    wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='salmon', colormap='Pastel1', collocations=False, stopwords = stop).generate(combined_corpus)\n",
    "\n",
    "    # Visualizing with a bar graph\n",
    "    plt.figure(figsize=(40, 30))\n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\");\n",
    " \n",
    "    n = 30\n",
    "   \n",
    "    # Initializing the Count Vectorizer, exluding words that appear less than 5 times\n",
    "    bagofwords = CountVectorizer(min_df = 5, stop_words = stop)\n",
    "    words = bagofwords.fit_transform(data['Description'])\n",
    "    counts = pd.DataFrame(columns = bagofwords.get_feature_names(), data = words.toarray())\n",
    "    counts.head()\n",
    "\n",
    "    # Getting word frequencies\n",
    "    frequencies = counts.sum().sort_values(ascending = False)[1:n]\n",
    "\n",
    "    # Visualizing\n",
    "    plt.figure(figsize = (16, 5))\n",
    "    sns.barplot(frequencies.index, frequencies.values, palette = 'inferno')\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(f\"Top {n} Most Frequent Words in the Corpus Inside\")\n",
    "    plt.show()\n",
    "    \n",
    "    return counts\n",
    "    \n",
    "    \n",
    "visualize_counts(merged);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now we can see the top words in a visually nice way with wordclouds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Data Scientist vs Data Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualizing words\n",
    "da_words = visualize_counts(da)\n",
    "ds_words = visualize_counts(ds)\n",
    "da_sf_words = visualize_counts(da_sf)\n",
    "ds_sf_words = visualize_counts(ds_sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Header Seperation\n",
    "\n",
    "Here, we wish to remove the header and make it in it's own qualitative variable. In order to do this, we have to think: what constitutes a header? Here are some characteristics:\n",
    "\n",
    "* It usually is much shorter in token length\n",
    "* It usually contains a certain set of \"headliny\" words\n",
    "\n",
    "Based on these two features alone, I bet that we can code up this separation.\n",
    "\n",
    "If this doesn't work, we can take a very likely set of the headliny words, then for every headliny word seen, we can increase the probability that it would be a headliny word. I have a feeling something simple like Naive Bayes classifier for headliny word would already be very accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit testing check function\n",
    "\n",
    "vocab = [\"Job\", \"Location\", \"Qualifications\", \"Perks\", \"Impact\", \"About\", \"Description\", \n",
    "         \"Compensation\", \"Why\", \"Summary\", \"Skills\", \"Preferred\", \"Who\", \"Requirements\",\n",
    "        \"Opportunity\"]\n",
    "vocab = [i.lower() for i in vocab]\n",
    "\n",
    "def check(sent, vocab):\n",
    "    ''' Checks if the heading vocab is inside the sentence you feed it in '''\n",
    "    contains = False\n",
    "    for word in vocab:\n",
    "        evaluate = [word in i for i in sent]\n",
    "        if True in evaluate:\n",
    "            contains = True\n",
    "            break\n",
    "    return contains\n",
    "\n",
    "a = ['This', 'position', 'can', 'be', 'based', 'remotely', 'anywhere', 'in', 'the', 'USA,', 'or', 'based', 'in', 'Tonawanda,', 'NY.']\n",
    "a = [i.lower() for i in a]\n",
    "\n",
    "check(a, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are a set of words that I want to require in order for the line to be a heading classification\n",
    "vocab = [\"Job\", \"Location\", \"Qualifications\", \"Perks\", \"Impact\", \"About\", \"Description\", \n",
    "         \"Compensation\", \"Why\", \"Summary\", \"Skills\", \"Preferred\", \"Who\", \"Requirements\",\n",
    "        \"Opportunity\", \"Salary\", \"Impact\", \"Work\", \"Join\", \"Technical\", \"Required\",\n",
    "        \"Overview\", \"What\", \"Benefits\", \"Vision\", \"Mission\", \"Responsibilities\",\n",
    "        'Experience', \"Need\", \"Forward\", \"Love\", \"Characteristics\", \"Desired\", \"Career\",\n",
    "        \"Notices\", 'Education']\n",
    "vocab = [i.lower() for i in vocab]\n",
    "\n",
    "# Example\n",
    "test  = merged['Description'].iloc[0]\n",
    "\n",
    "def header_separation(desc):\n",
    "    ''' Inputs: Job Description for ONE entry\n",
    "    Outputs: A dataframe with Heading as a column, and Heading text mapped to it in another\n",
    "    \n",
    "    This function constantly flips between list methods and string methods to do the calculations.\n",
    "    '''\n",
    "    \n",
    "    def check(sent, vocab):\n",
    "        ''' Checks if the heading vocab is inside the sentence you feed it in '''\n",
    "        contains = False\n",
    "        for word in vocab:\n",
    "            evaluate = [word in i for i in sent]\n",
    "            if True in evaluate:\n",
    "                contains = True\n",
    "                break\n",
    "        return contains\n",
    "    \n",
    "    # Separating it by new line and making it a list of lists.\n",
    "    desc = [i.split() for i in desc.split('\\n')]\n",
    "    \n",
    "    # Removing all empty lists (entries)\n",
    "    while [] in desc: desc.remove([]) \n",
    "        \n",
    "    # Prepending: Designating the first header to be called 'Entry'\n",
    "    headers = [\"Entry\"]\n",
    "    master_content = []\n",
    "    current_content = []\n",
    "\n",
    "    # Code to classify header = If the line has less than 6 tokens, I consider it a header.\n",
    "    # Then I take everything in between headers as the current header content\n",
    "    for i in desc:\n",
    "        # Checking if the heading vocab is inside the line\n",
    "        lowered_sent = [e.lower() for e in i]\n",
    "        if len(i) < 6 and check(lowered_sent, vocab):\n",
    "#             print(\"============================================================\\n\")\n",
    "#             print(current_content)\n",
    "            master_content.append([\" \".join(i) for i in current_content])\n",
    "            current_content.clear()\n",
    "            current_header = \" \".join(i)\n",
    "            headers.append(current_header)\n",
    "        else:\n",
    "            current_content.append(i)\n",
    "            \n",
    "    # Adjusting for the prepend to add the last entry manually\n",
    "    master_content.append([\" \".join(i) for i in current_content])\n",
    "    \n",
    "    # Need to convert from list to just a string\n",
    "    stringed_master_content = []\n",
    "    \n",
    "    # Converting the content from a list to just a string\n",
    "    for i in master_content:\n",
    "        if len(i) >= 1:\n",
    "            stringed_master_content.append(i[0])\n",
    "        else:\n",
    "            stringed_master_content.append('')\n",
    "    \n",
    "    # Using extracted dictionary to create a new dataframe of Heading and its text\n",
    "    output = pd.DataFrame({\"Heading\": headers, \"Heading Text\": stringed_master_content})\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "output = header_separation(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Header Separation on Rest of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if the tokens start with capital letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading_counts = headings['Heading'].value_counts()\n",
    "heading_counts = pd.DataFrame({\"Heading Title\": heading_counts.index, \"Frequency\": heading_counts.values})\n",
    "heading_counts.iloc[1:, :].to_csv(\"heading_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "def transform(line):\n",
    "    ''' This function is used to remove the punctuations from the dataset '''\n",
    "    # Removing punctuations\n",
    "    no_punct = \"\"\n",
    "    for char in line:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "            \n",
    "    return no_punct.lower()\n",
    "\n",
    "\n",
    "a = 'Requirements: LOVIE;;'\n",
    "transform(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we successfully got the dataframe of headings for one job entry, we need to try to expand it on the rest of the dataset.\n",
    "\n",
    "Here's a useful article on Python vectorization, which is preferred over iterating through the dataframe for its speed: https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#essential-basic-functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for each job posting, based on the ID, I will create new dataframe containing the headings and mapping it to the ID\n",
    "\n",
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "def transform(line):\n",
    "    ''' This function is used to remove the punctuations from the dataset '''\n",
    "    # Removing punctuations\n",
    "    no_punct = \"\"\n",
    "    for char in line:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "            \n",
    "    return no_punct.lower()\n",
    "\n",
    "\n",
    "def synthesize_headings(df):\n",
    "    ''' Inputs: Job descriptions dataframe \n",
    "    Outputs: Original dataframe with ID column, Heading synthesized dataframe\n",
    "    '''\n",
    "    \n",
    "    # Creating a unique ID for the df\n",
    "    df['ID'] = np.arange(df.shape[0])\n",
    "\n",
    "    heading = pd.DataFrame(columns = [\"ID\", \"Heading\", \"Heading Text\"])\n",
    "    job_id = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        # Mini header represents the headings dataframe for ONE given row in the Linkedin dataframe\n",
    "        # The columns it has is Heading and Heading Text\n",
    "        mini_header = header_separation(df['Description'].iloc[i])\n",
    "        heading = pd.concat([heading, mini_header])\n",
    "\n",
    "        # Manually creating the Job ID row based on the number of rows that results in the mini heading df\n",
    "        job_id += [df['ID'].iloc[i]] * mini_header.shape[0]\n",
    "\n",
    "    # Adding Job ID Column into the final heading dataframe\n",
    "    heading['ID'] = job_id\n",
    "    \n",
    "    return df, heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged will be the merged dataframe with the ID column attached, \n",
    "merged, headings = synthesize_headings(merged)\n",
    "\n",
    "# Cleaning the headings column of the merged headings dataframe\n",
    "headings['Heading'] = headings['Heading'].apply(transform)\n",
    "\n",
    "# Now adding a label onto based on Professor Sandra's suggestion\n",
    "heading_labels = pd.read_csv('headings/heading_labels.csv')\n",
    "\n",
    "headings_df = pd.merge(headings, heading_labels, left_on = \"Heading\", right_on = \"Heading Title\", how = \"inner\")\n",
    "headings_df.drop(['Unnamed: 0', 'Unnamed: 4', \"Heading\"], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings_df.to_csv('headings/headings_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting heading counts\n",
    "heading_counts = headings['Heading'].value_counts()\n",
    "heading_counts = pd.DataFrame({\"Heading Title\": heading_counts.index, \"Frequency\": heading_counts.values})\n",
    "heading_counts.iloc[1:, :].to_csv(\"heading_counts.csv\")\n",
    "\n",
    "# Converting all to lowercase and aggregating\n",
    "heading_counts['Heading Title'] = heading_counts['Heading Title'].apply(transform)\n",
    "heading_counts.shape\n",
    "\n",
    "heading_counts.groupby(\"Heading Title\").sum().sort_values(\"Frequency\", ascending = False).reset_index().iloc[1:,:].to_csv(\"heading_counts_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
